var store = [{
        "title": "HNSW: Fast Approximate Nearest Neighbors with Hierarchical Graphs",
        "excerpt":"HNSW: Fast Approximate Nearest Neighbors with Hierarchical Graphs 1. Problem Statement Traditional nearest neighbor search becomes computationally expensive in high-dimensional spaces (the “curse of dimensionality”) Exact search (like brute-force) is O(n) per query - infeasible for large datasets Real-world applications require fast similarity search in recommendation systems, NLP, and image...","categories": ["machine-learning"],
        "tags": ["ann","vector-search","algorithms"],
        "url": "/machine-learning/hnsw-fast-approximate-nearest-neighbors-with-hierarchical-graphs/",
        "teaser": null
      },{
        "title": "Transformers",
        "excerpt":"title: Transformers date: 2024-01-02 12:00:00 categories:[AI, Text Processing] tags: [ML, AI, GenAI] author: “Dev” — Text Generation with Transformers: Fine-Tuning for Specific Tasks Transformers have revolutionized Natural Language Processing (NLP), achieving state-of-the-art results in various tasks, including text generation. Unlike recurrent neural networks (RNNs), transformers process entire sequences in parallel,...","categories": [],
        "tags": [],
        "url": "/transformers/",
        "teaser": null
      },{
        "title": "Quantization",
        "excerpt":"Title: Quantization date: 2024-01-02 12:00:00 categories:[AI, Text Processing, Quantization] tags: [ML, AI, GenAI] author: “Amit Tiwari” — Quantization is a technique for reducing the model size by compressing the model weights from a high-precision value to a low-precision value. The weights of a language model are the vectors that can...","categories": [],
        "tags": [],
        "url": "/Quantization/",
        "teaser": null
      }]
